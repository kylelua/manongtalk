<!DOCTYPE html><html lang="zh-Hans"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title> 如何用Python实现一个简单的人工神经网络(Artificial Neural Network) | 码农说</title><meta name="description" content="如何用Python实现一个简单的人工神经网络(Artificial Neural Network) - 卤蛋侠"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="short icon" href="/icon0.png"><link rel="stylesheet" href="/css/casual.css"><link rel="stylesheet" href="/css/semantic.min.css"><link rel="search" type="application/opensearchdescription+xml" href="http://manongtalk.com/atom.xml" title="码农说"></head><body><div class="sidebar"><div class="ui vertical inverted menu"><div class="h100"></div><h3 class="ui inverted aligned icon header"><div class="content"><a href="/" class="title-link">码农说</a></div></h3><div class="h50"></div><div class="side-nav"><a href="/" target="_self" class="item">HOME<i class="icon home"></i></a><a href="/archives" target="_self" class="item">ARCHIVE<i class="icon archive"></i></a><a href="/tags" target="_self" class="item">TAGS<i class="icon tags"></i></a><a href="/about" target="_self" class="item">INFO<i class="icon info"></i></a></div><div class="item"><div class="ui inverted transparent icon input"><input type="text" placeholder="Search..." class="st-default-search-input"><i class="search icon"></i></div></div><div class="h50"></div></div><div class="h50 mq"><a class="ui teal big label"><i class="content icon"></i></a></div><div class="author-info"><a href="/" class="img-link"><img src="/icon1.png" class="author-photo ui tiny circular image"></a><h4 class="ui aligned icon header"><div class="content">卤蛋侠</div></h4><p class="author-desc">一个程序员的日常 | iOS & Android | Computer Vision | Artificial Intelligence</p><div class="social-outer"><div class="social-inner"><a href="https://raw.githubusercontent.com/kylelua/manongtalk/master/qrcode.jpg" target="_blank" class="social-link"><i class="icon wechat"></i></a></div></div></div></div><div class="main"><div class="wrap"><section class="container"><div class="post"><article class="post-block"><h1 class="post-title">如何用Python实现一个简单的人工神经网络(Artificial Neural Network)</h1><div class="post-info"><div class="post-date"><h6 class="ui header"><i class="calendar icon"></i><div class="content">Nov 13, 2016</div></h6></div></div><div class="post-content"><p>人工神经网络(Artificial Neural Network，ANN)的最初灵感来自于大脑神经系统的工作方式。人们的大脑通过从例子中总结经验来学习新的东西。经过训练的ANN同样可以用于图像识别和数据分类。生物学告诉我们，大脑里有大量的神经元，构成了复杂的网络。每个神经元之间通过突触传递介质（如：乙酰胆碱，多巴胺等）从而传递信息。我们可以把模型简化为：每个神经元可以许多其它神经细胞对其进行输入，然后它把这些输入加权，如果加权后的值高于一定阈值，则会激发该细胞产生一个输出。<br><a id="more"></a><br><img src="https://raw.githubusercontent.com/kylelua/manongtalk/master/img/2016-10-13-ann/Artificial-neural-network.png" alt=""></p>
<p>在计算机科学中， 我们完全可以模仿这个生物过程，造出一个人造神经网络。这个神经网络其实可以理解为生物神经系统的抽象。为了做简单说明，这篇文章把只考虑一个非常简化的模型：网络只有两层；并且试图解决一个线性的归类问题。</p>
<p><img src="https://raw.githubusercontent.com/kylelua/manongtalk/master/img/2016-10-13-ann/Artificial-neural-network1.png" alt=""></p>
<p>假设我们有一组训练集合，如下面的表格：</p>
<p><img src="https://raw.githubusercontent.com/kylelua/manongtalk/master/img/2016-10-13-ann/table1.png" alt=""></p>
<p>我们希望下次输入后，计算机能预言出合理的输出结果。（仔细看表格我们可以总结出规律，输出只和输入3相关，所以结果应该是1）</p>
<p><img src="https://raw.githubusercontent.com/kylelua/manongtalk/master/img/2016-10-13-ann/table2.png" alt=""></p>
<p>训练的过程如下：</p>
<ol>
<li><p>向前推进：<br>把输入的参数加权求和（权重为随机数）：<br><strong>Y = Weight1 x Input1 + Weight2 x Input2 + Wight3 x Input3</strong><br>把求和的结果通过sigmoid函数归一化，从而获得一个0和1之间的结果。<br>注：sigmoid 函数公式为  <em>Y = 1 / (1 + exp(-X))</em></p>
</li>
<li><p>向后检验：<br>计算误差。在我们的例子中，我把误差定义为真实的输出于预测输出的差。之后我们根据误差重新调整权重。设 权重Weight, 误差Error, 输入Input, 输出Output, 则公式如下：<br><em>Weight = Weight + Error x Input x Output x ( 1 - Output )</em></p>
</li>
</ol>
<p>反复重复以上步骤。</p>
<p>以下是python代码实现：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div></pre></td><td class="code"><pre><div class="line">from numpy import *</div><div class="line"> </div><div class="line">class NeuralNet(object):</div><div class="line">    def __init__(self):</div><div class="line">        # Generate random numbers</div><div class="line">        random.seed(1)</div><div class="line"> </div><div class="line">        # Assign random weights to a 3 x 1 matrix,</div><div class="line">        self.synaptic_weights = 2 * random.random((3, 1)) - 1</div><div class="line"> </div><div class="line">    # The Sigmoid function</div><div class="line">    def __sigmoid(self, x):</div><div class="line">        return 1 / (1 + exp(-x))</div><div class="line"> </div><div class="line">    # The derivative of the Sigmoid function.</div><div class="line">    # This is the gradient of the Sigmoid curve.</div><div class="line">    def __sigmoid_derivative(self, x):</div><div class="line">        return x * (1 - x)</div><div class="line"> </div><div class="line">    # Train the neural network and adjust the weights each time.</div><div class="line">    def train(self, inputs, outputs, training_iterations):</div><div class="line">        for iteration in xrange(training_iterations):</div><div class="line"> </div><div class="line">            # Pass the training set through the network.</div><div class="line">            output = self.learn(inputs)</div><div class="line"> </div><div class="line">            # Calculate the error</div><div class="line">            error = outputs - output</div><div class="line"> </div><div class="line">            # Adjust the weights by a factor</div><div class="line">            factor = dot(inputs.T, error * self.__sigmoid_derivative(output))</div><div class="line">            self.synaptic_weights += factor</div><div class="line"> </div><div class="line">    # The neural network thinks.</div><div class="line">    def learn(self, inputs):</div><div class="line">        return self.__sigmoid(dot(inputs, self.synaptic_weights))</div><div class="line"> </div><div class="line">if __name__ == &quot;__main__&quot;:</div><div class="line"> </div><div class="line">    #Initialize</div><div class="line">    neural_network = NeuralNet()</div><div class="line"> </div><div class="line">    # The training set.</div><div class="line">    inputs = array([[0, 1, 1], [1, 0, 0], [1, 0, 1]])</div><div class="line">    outputs = array([[1, 0, 1]]).T</div><div class="line"> </div><div class="line">    # Train the neural network</div><div class="line">    neural_network.train(inputs, outputs, 10000)</div><div class="line"> </div><div class="line">    # Test the neural network with a test example.</div><div class="line">    print neural_network.learn(array([1, 0, 1]))</div></pre></td></tr></table></figure>
<p>输出结果：当迭代10次以后，神经网络的预测结果是0.6598. 和正确答案1相比，这个结果并不够好。我们尝试着增加迭代次数，可以看到当迭代超过100次时预测结果达到0.8768，而迭代超过10000次后结果是0.9898，已经接近实际值。</p>
</div></article></div></section><footer><div class="paginator"><a href="/2016/11/12/2016-11-12-archi-03/" class="next"><button class="ui button teal">NEXT</button></a></div><div class="copyright"><p>© 2016 <a href="http://manongtalk.com">卤蛋侠</a>, powered by <a href="https://hexo.io/" target="_blank">Hexo</a> and theme by <a href="https://github.com/littlewin-wang/hexo-theme-casual" target="_blank">casual</a></p></div></footer></div><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.1.0/jquery.min.js"></script><script src="/js/jquery.scrollex.js"></script><script src="/js/jquery.goup.min.js"></script><script src="/js/semantic.min.js"></script><script src="/js/casual.js"></script><script async src="//cdn.bootcss.com/mathjax/2.6.1/MathJax.js?config=TeX-MML-AM_CHTML"></script><script>$(document).ready(function(){$.goup({trigger:100,bottomOffset:100,locationOffset: 0,title:'',titleAsText:true});});</script><script>(function(w,d,t,u,n,s,e){w['SwiftypeObject']=n;w[n]=w[n]||function(){(w[n].q=w[n].q||[]).push(arguments);};s=d.createElement(t);e=d.getElementsByTagName(t)[0];s.async=1;s.src=u;e.parentNode.insertBefore(s,e);})(window,document,'script','//s.swiftypecdn.com/install/v2/st.js','_st');
_st('install','TvAnFS4AVxjiJUvrZJRB','2.0.0');</script><script>(function(b,o,i,l,e,r){b.GoogleAnalyticsObject=l;b[l]||(b[l]=function(){(b[l].q=b[l].q||[]).push(arguments)});b[l].l=+new Date;e=o.createElement(i);r=o.getElementsByTagName(i)[0];e.src='//www.google-analytics.com/analytics.js';r.parentNode.insertBefore(e,r)}(window,document,'script','ga'));ga('create',"UA-83962536-1",'auto');ga('send','pageview');</script></div></body></html>